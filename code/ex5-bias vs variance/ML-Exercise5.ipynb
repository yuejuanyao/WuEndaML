{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习练习 5 - 偏差和方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章代码涵盖了基于Python的解决方案，用于Coursera机器学习课程的第五个编程练习。 请参考[练习文本](ex5.pdf)了解详细的说明和公式。\n",
    "\n",
    "代码修改并注释：黄海广，haiguang2000@qq.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as opt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"for ex5\n",
    "    d['X'] shape = (12, 1)\n",
    "    pandas has trouble taking this 2d ndarray to construct a dataframe, so I ravel\n",
    "    the results\n",
    "    \"\"\"\n",
    "    d = sio.loadmat('ex5data1.mat')\n",
    "    return map(np.ravel, [d['X'], d['y'], d['Xval'], d['yval'], d['Xtest'], d['ytest']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, Xval, yval, Xtest, ytest = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcm0lEQVR4nO3df5Dcd33f8de7p1MkFXUswh11LM2AUjcCp4khiseJiSp+pYZmBOnQJJ4mdRNmrHRggGnSBJLGTTzJNEwb3NKmRE4xdqeUHwkwqJSQuGBFkGKIIMagWNREobGD4xONMEpOxqfj0z92HUuOzjrZ2tv77D0eMze7+93v3b7nOzo977v73e9Way0AQF/+xrgHAADOn4ADQIcEHAA6JOAA0CEBB4AOrRv3AMtx9dVXtw996EPjHgMAxqHOtrCLPfAvf/nL4x4BAFaVLgIOAJxJwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA6tG/cAANCjA0fmsu/g0dx7fD7btmzK3l3bs3vH7Io9vj1wADhPB47M5fr9hzN34qFctHE6cyceyvX7D+fAkbkVm0HAAeA87Tt4NNNTlU3r16VqcDk9Vdl38OiKzSDgAHCe7j0+n43TU2cs2zg9lfuOz6/YDAIOAOdp25ZNObmweMaykwuL2bpl04rNIOAAcJ727tqehcWW+YdPpbXB5cJiy95d21dsBgEHgPO0e8dsbthzWWY3b8iDJxcyu3lDbthz2Yoehe5tZADwBOzeMbuiwX4se+AA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdGlnAq2pDVX2yqj5TVYer6heGy2+pqj+uqjuHX5ePagYAmFSj/DjRryV5QWvtL6pqOsnHquq3hvf9y9bab47wsQFgoo0s4K21luQvhjenh19tVI8HAGvJSF8Dr6qpqrozyVyS21prnxje9UtVdVdV3VhV37DE915XVYeq6tCxY8dGOSYAdGekAW+tLbbWLk+yNckVVfWtSd6QZEeS70zy1CQ/vcT33tRa29la2zkzMzPKMQGgOytyFHpr7StJDiS5urV2fxv4WpK3JbliJWYAgEkyyqPQZ6rqouH1jUlelORIVV08XFZJXp7kc6OaAQAm1SiPQr84ya1VNZXBHwrvbq19oKo+UlUzSSrJnUl+fIQzAMCTcuDIXPYdPJp7j89n25ZN2btre3bvmB33WKnBweKr286dO9uhQ4fGPQYAa8yBI3O5fv/hTE9VNk5P5eTCYhYWW27Yc9lKRrzOttCZ2ABgCfsOHs30VGXT+nWpGlxOT1X2HTw67tEEHACWcu/x+Wycnjpj2cbpqdx3fH5MEz1KwAFgCdu2bMrJhcUzlp1cWMzWLZvGNNGjBBwAlrB31/YsLLbMP3wqrQ0uFxZb9u7aPu7RBBwAlrJ7x2xu2HNZZjdvyIMnFzK7ecNKH8C2pFG+jQwAurd7x+yqCPZj2QMHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdGhkAa+qDVX1yar6TFUdrqpfGC5/ZlV9oqruqap3VdX6Uc0AAJNqlHvgX0vygtbatye5PMnVVXVlkjcmubG1dmmS40leOcIZAGAijSzgbeAvhjenh18tyQuS/OZw+a1JXj6qGQBgUo30NfCqmqqqO5PMJbktyR8l+Upr7dRwlfuSXLLE915XVYeq6tCxY8dGOSYAdGekAW+tLbbWLk+yNckVSZ51ttWW+N6bWms7W2s7Z2ZmRjkmAHRnRY5Cb619JcmBJFcmuaiq1g3v2prkSysxAwBMklEehT5TVRcNr29M8qIkdye5Pckrhqtdm+T9o5oBACbVunOv8oRdnOTWqprK4A+Fd7fWPlBVf5jknVX1i0n+IMlbRzgDAEykkQW8tXZXkuecZfnRDF4PBwCeIGdiA4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOjSzgVbWtqm6vqrur6nBVvXa4/Oer6k+r6s7h10tHNQMATKp1I/zZp5L8RGvt01W1Ocmnquq24X03ttb+3QgfGwAm2sgC3lq7P8n9w+snquruJJeM6vEAYC1ZkdfAq+oZSZ6T5BPDRa+uqruq6uaq2rLE91xXVYeq6tCxY8dWYkwA6MbIA15VT0nyniSva619Nclbknxzkssz2EP/lbN9X2vtptbaztbazpmZmVGPCQBdGWnAq2o6g3i/vbX23iRprT3QWltsrX09ya8nuWKUMwDAJBrlUeiV5K1J7m6tvem05Refttr3J/ncqGYAgEk1yqPQr0ryI0k+W1V3Dpf9TJJrquryJC3JF5PsHeEMADCRRnkU+seS1Fnu+uCoHhMA1gpnYgOADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA6tG/cAAKx+B47MZd/Bo7n3+Hy2bdmUvbu2Z/eO2XGPtabZAwfgcR04Mpfr9x/O3ImHctHG6cydeCjX7z+cA0fmxj3amibgADyufQePZnqqsmn9ulQNLqenKvsOHh33aGuagAPwuO49Pp+N01NnLNs4PZX7js+PaSISAQfgHLZt2ZSTC4tnLDu5sJitWzaNaSISAQfgHPbu2p6FxZb5h0+ltcHlwmLL3l3bxz3amibgADyu3Ttmc8OeyzK7eUMePLmQ2c0bcsOeyxyFPmbeRgbAOe3eMSvYq4w9cADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQyMLeFVtq6rbq+ruqjpcVa8dLn9qVd1WVfcML7eMagYAmFSj3AM/leQnWmvPSnJlkldV1bOTvD7Jh1trlyb58PA2AHAeRhbw1tr9rbVPD6+fSHJ3kkuSvCzJrcPVbk3y8lHNAACTakVeA6+qZyR5TpJPJHl6a+3+ZBD5JLNLfM91VXWoqg4dO3ZsJcYEgG6MPOBV9ZQk70nyutbaV5f7fa21m1prO1trO2dmZkY3IAB0aKQBr6rpDOL99tbae4eLH6iqi4f3X5xkbpQzAMAkGuVR6JXkrUnubq296bS79ie5dnj92iTvH9UMADCpzhnwqtr+BH/2VUl+JMkLqurO4ddLk/xykhdX1T1JXjy8DQCch3XLWOeWqrokye8nOZjko621z57rm1prH0tSS9z9wuWPCAA81jkD3lrbVVXrk3xnkt1J/mdVPaW19tRRDwcAnN05A15Vz0vyPcOvi5J8IMlHRzwXAPA4lvMU+u8mOZTk3yT5YGvt4dGOBACcy3IC/o0ZHJC2K8lrqurrST7eWvu5kU4GACxpOa+Bf6WqjibZlmRrku9OMj3qwQCApS3nNfA/SvL5JB9L8mtJftTT6AAwXst5Cv3S1trXRz4JALBsyzkT2zdV1fuqaq6qHqiq91TV1pFPBgAsaTkBf1sGpz/9pgw+DvR/DJcBAGOynIDPtNbe1lo7Nfy6JYmPBwOAMVpOwL9cVT9cVVPDrx9O8v9GPRgAsLTlBPzHkvxAkj9Lcn+SVwyXAQBjspz3gf9Jkj0rMAsAsExLBryq3vx439hae82FHwcAWI7H2wP/R0l+NsmWJMdXZhwAYDkeL+BfTXIgg7eQPX9FpgEAluXxAv5rST6UZHsGn0b2iErShssBgDFY8ij01tqbW2vPSnJza237aV/PbK2JNwCM0TnfRtZa++crMQgAsHzLeR84ALDKCDgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOjQyAJeVTdX1VxVfe60ZT9fVX9aVXcOv146qscHgEk2yj3wW5JcfZblN7bWLh9+fXCEjw8AE2tkAW+tHUzy56P6+QCwlo3jNfBXV9Vdw6fYt4zh8QGgeysd8Lck+eYklye5P8mvLLViVV1XVYeq6tCxY8dWaj6AVePAkblcc9Mded4bP5JrbrojB47MjXskVpEVDXhr7YHW2mJr7etJfj3JFY+z7k2ttZ2ttZ0zMzMrNyTAKnDgyFyu3384cyceykUbpzN34qFcv/+wiPNXVjTgVXXxaTe/P8nnlloXYC3bd/Bopqcqm9avS9Xgcnqqsu/g0XGPxiqxblQ/uKrekWR3kqdV1X1J/nWS3VV1eZKW5ItJ9o7q8QF6du/x+Vy0cfqMZRunp3Lf8fkxTcRqM7KAt9auOcvit47q8QAmybYtmzJ34qFsWv/of9MnFxazdcumMU7FauJMbACr0N5d27Ow2DL/8Km0NrhcWGzZu2v7uEdjlRBwgFVo947Z3LDnssxu3pAHTy5kdvOG3LDnsuzeMTvu0VglRvYUOgBPzu4ds4LNkuyBA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB0ScADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMjC3hV3VxVc1X1udOWPbWqbquqe4aXW0b1+AAwyUa5B35Lkqsfs+z1ST7cWrs0yYeHtwGA8zSygLfWDib588csflmSW4fXb03y8lE9PgBMspV+DfzprbX7k2R4ObvUilV1XVUdqqpDx44dW7EBAaAHq/YgttbaTa21na21nTMzM+MeBwBWlZUO+ANVdXGSDC/nVvjxAWAirHTA9ye5dnj92iTvX+HHB4CJMMq3kb0jyceTfEtV3VdVr0zyy0leXFX3JHnx8DYAcJ7WjeoHt9auWeKuF47qMQFgrVi1B7EBAEsTcADokIADQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6NC6cQ8AME4Hjsxl38Gjuff4fLZt2ZS9u7Zn947ZcY8F52QPHFizDhyZy/X7D2fuxEO5aON05k48lOv3H86BI3PjHg3OScCBNWvfwaOZnqpsWr8uVYPL6anKvoNHxz0anJOAA2vWvcfns3F66oxlG6enct/x+TFNBMsn4MCatW3LppxcWDxj2cmFxWzdsmlME8HyCTiwZu3dtT0Liy3zD59Ka4PLhcWWvbu2j3s0OCcBB9as3Ttmc8OeyzK7eUMePLmQ2c0bcsOeyxyFThe8jQxY03bvmBVsumQPHAA6JOAA0CEBB4AOCTgAdEjAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMABoEMCDgAdEnAA6JCAA0CHBBwAOiTgANAhAQeADgk4AHRIwAGgQwIOAB1aN44HraovJjmRZDHJqdbaznHMAQC9GkvAh57fWvvyGB8fALrlKXQA6NC4At6S/E5VfaqqrjvbClV1XVUdqqpDx44dW+HxAGB1G1fAr2qtPTfJS5K8qqp2PXaF1tpNrbWdrbWdMzMzKz8hAKxiYwl4a+1Lw8u5JO9LcsU45gCAXq14wKvqb1bV5keuJ/neJJ9b6TkAoGfjOAr96UneV1WPPP5/b619aAxzAEC3VjzgrbWjSb59pR8XACaJt5EBQIcEHAA6JOAA0CEBB4AOCTgAdEjAAaBD4/w0solw4Mhc9h08mnuPz2fblk3Zu2t7du+YHfdY0D2/W/D47IE/CQeOzOX6/Yczd+KhXLRxOnMnHsr1+w/nwJG5cY8GXfO7Becm4E/CvoNHMz1V2bR+XaoGl9NTlX0Hj457NOia3y04NwF/Eu49Pp+N01NnLNs4PZX7js+PaSKYDH634NwE/EnYtmVTTi4snrHs5MJitm7ZNKaJYDL43YJzE/AnYe+u7VlYbJl/+FRaG1wuLLbs3bV93KNB1/xuwbkJ+JOwe8dsbthzWWY3b8iDJxcyu3lDbthzmSNl4UnyuwXnVq21cc9wTjt37myHDh0a9xgAMA51toX2wAGgQwIOAB0ScADo0Jo9larTNALQszW5B+40jQD0bk3ugZ9+msYk2bR+XeYfPpV9B4+uib1wzz4A9G9N7oGv5dM0evYBYDKsyYCv5dM0+pAIgMmwJgO+lk/TuJaffQCYJGsy4Gv5NI1r+dkHgEmyJg9iSwYRXwvBfqy9u7bn+v2HM//wqWycnsrJhcU18+zDSnGQILAS1mzA16rdO2ZzQwavhd93fD5bBeaCeuQgwempOuMgwRuSFd3G/oiAyefDTOACuuamOzJ34qG/eotiksw/fCqzmzfkHddduSIznP5HxOnPsqyVl4lgAvkwExi11XCQoHcawNog4HABrYaDBFfDHxHA6Ak4XECr4S2Kq+GPCGD0BBwuoNXwFsXV8EcEMHoOYoMJ9MhR6N5pABPhrAexeRsZTKC1ep4DWEs8hQ4AHRJwAOiQp9AZGWcDAxgde+CMhM8dBxgtAWcknA0MYLQEnJFwNjCA0RJwRsLZwABGS8AZCWcDAxgtAWckVsMpRQEmmbeRMTLOBgYwOvbAAaBDAg4AHRJwAOiQgANAhwQcADok4ADQobEEvKqurqrPV9UXqur145gBAHq24gGvqqkkv5rkJUmeneSaqnr2Ss8BAD0bxx74FUm+0Fo72lp7OMk7k7xsDHMAQLfGEfBLktx72u37hsvOUFXXVdWhqjp07NixFRsOAHowjoDXWZa1v7agtZtaaztbaztnZmZWYCwA6Mc4An5fkm2n3d6a5EtjmAMAujWOgP9+kkur6plVtT7JDyXZP4Y5AKBbK/5pZK21U1X16iS/nWQqyc2ttcMrPQcA9GwsHyfaWvtgkg+O47EBYBI4ExsAdKha+2sHgK86VXUsyf8d9xwr7GlJvjzuIdYg2308bPfxsN3H43y3+5dba1c/dmEXAV+LqupQa23nuOdYa2z38bDdx8N2H48Ltd09hQ4AHRJwAOiQgK9eN417gDXKdh8P2308bPfxuCDb3WvgANAhe+AA0CEBB4AOCfgqVVU/WVWtqp42vF1V9eaq+kJV3VVVzx33jJOkqv5tVR0Zbtv3VdVFp933huF2/3xV/YNxzjmJqurq4bb9QlW9ftzzTKqq2lZVt1fV3VV1uKpeO1z+1Kq6raruGV5uGfesk6aqpqrqD6rqA8Pbz6yqTwy3+buGnwty3gR8FaqqbUlenORPTlv8kiSXDr+uS/KWMYw2yW5L8q2ttW9L8n+SvCFJqurZGXzgzmVJrk7yn6tqamxTTpjhtvzVDP59PzvJNcNtzoV3KslPtNaeleTKJK8abuvXJ/lwa+3SJB8e3ubCem2Su0+7/cYkNw63+fEkr3wiP1TAV6cbk/xUzvyc9Jcl+a9t4I4kF1XVxWOZbgK11n6ntXZqePOODD7mNhls93e21r7WWvvjJF9IcsU4ZpxQVyT5QmvtaGvt4STvzGCbc4G11u5vrX16eP1EBkG5JIPtfetwtVuTvHw8E06mqtqa5B8m+S/D25XkBUl+c7jKE97mAr7KVNWeJH/aWvvMY+66JMm9p92+b7iMC+/HkvzW8LrtPlq27xhU1TOSPCfJJ5I8vbV2fzKIfJLZ8U02kf59BjtkXx/e/sYkXzlth+EJ/5sfy6eRrXVV9b+S/O2z3PWzSX4myfee7dvOssx7AM/D42331tr7h+v8bAZPNb79kW87y/q2+4Vj+66wqnpKkvckeV1r7auDHUJGoaq+L8lca+1TVbX7kcVnWfUJ/ZsX8DForb3obMur6u8leWaSzwx/qbYm+XRVXZHBX2nbTlt9a5IvjXjUibLUdn9EVV2b5PuSvLA9eoIE2320bN8VVFXTGcT77a219w4XP1BVF7fW7h++LDc3vgknzlVJ9lTVS5NsSPK3Mtgjv6iq1g33wp/wv3lPoa8irbXPttZmW2vPaK09I4P/3J7bWvuzJPuT/NPh0ehXJnnwkae9ePKq6uokP51kT2tt/rS79if5oar6hqp6ZgYHEX5yHDNOqN9PcunwqNz1GRwwuH/MM02k4Wuvb01yd2vtTafdtT/JtcPr1yZ5/0rPNqlaa29orW0d/n/+Q0k+0lr7J0luT/KK4WpPeJvbA+/HB5O8NIODqOaT/Oh4x5k4/ynJNyS5bfjsxx2ttR9vrR2uqncn+cMMnlp/VWttcYxzTpTW2qmqenWS304yleTm1trhMY81qa5K8iNJPltVdw6X/UySX07y7qp6ZQbvfPnHY5pvLfnpJO+sql9M8gcZ/GF13pxKFQA65Cl0AOiQgANAhwQcADok4ADQIQEHgA4JOAB0SMBhjaiq11XVpgv0s26pqlece83x/kyYZAIOa8frkpxXwH10KqxeAg6dqaqfqqrXDK/fWFUfGV5/YVX9t6p6S1UdqqrDVfULw/tek+SbktxeVbcPl31vVX28qj5dVb8x/JCLVNUXq+r6qvpYlnFWrqr6jqr63ar6VFX9dlVdXFXPqqpPnrbOM6rqrqXWv8CbCNYEAYf+HEzyPcPrO5M8ZfghFc9L8tEMPl1tZ5JvS/L3q+rbWmtvzuADE57fWnt+VT0tyb9K8qLW2nOTHEryL057jIdaa89rrb3z8QYZPu5/TPKK1tp3JLk5yS+11u5Osr6qtg9X/cEMTtd51vWf3OaAtcm50KE/n0ryHVW1OcnXknw6g5B/T5LXJPmBqroug9/vi5M8O8ldj/kZVw6X/97w3O/rk3z8tPvftcxZviXJt+bRc8hPJXnkQ3beneQHMjjX9g8Ovx5vfeA8CDh0prW2UFVfzOADbf53BnF+fpJvTnIyyU8m+c7W2vGquiWDjzF8rEpyW2vtmiUe5i+XOU4lOdxa+66z3PeuJL9RVe8djN3uGX5k7lLrA+fBU+jQp4MZhPpgBk+b/3iSOzP4vOG/TPJgVT09yUtO+54TSTYPr9+R5Kqq+jtJUlWbqurvPoE5Pp9kpqq+a/hzpqvqsiRprf1RksUkP5dH9+iXXB84PwIOffpoBk+Pf7y19kCSh5J8tLX2mQw+nvBwBq8v/95p33NTkt+qqttba8eS/LMk7xgeXHZHkh3nO0Rr7eEMPtf4jVX1mQz+iPju01Z5V5IfzuDp9OWsDyyTjxMFgA7ZAweADjmIDVhSVf1qkqses/g/tNbeNo55gEd5Ch0AOuQpdADokIADQIcEHAA6JOAA0KH/D7nE0DpI6LY+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'water_level':X, 'flow':y})\n",
    "\n",
    "sns.lmplot('water_level', 'flow', data=df, fit_reg=False, height=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Xval, Xtest = [np.insert(x.reshape(x.shape[0], 1), 0, np.ones(x.shape[0]), axis=1) for x in (X, Xval, Xtest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代价函数\n",
    "<img style=\"float: left;\" src=\"../img/linear_cost.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    \"\"\"\n",
    "    X: R(m*n), m records, n features\n",
    "    y: R(m)\n",
    "    theta : R(n), linear regression parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "\n",
    "    inner = X @ theta - y  # R(m*1)\n",
    "\n",
    "    # 1*m @ m*1 = 1*1 in matrix multiplication\n",
    "    # but you know numpy didn't do transpose in 1d array, so here is just a\n",
    "    # vector inner product to itselves\n",
    "    square_sum = inner.T @ inner\n",
    "    cost = square_sum / (2 * m)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303.9515255535976"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.ones(X.shape[1])\n",
    "cost(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度\n",
    "<img style=\"float: left;\" src=\"../img/linear_gradient.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    inner = X.T @ (X @ theta - y)  # (m,n).T @ (m, 1) -> (n, 1)\n",
    "\n",
    "    return inner / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则化梯度\n",
    "<img style=\"float: left;\" src=\"../img/linear_reg_gradient.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_gradient(theta, X, y, l=1):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    regularized_term = theta.copy()  # same shape as theta\n",
    "    regularized_term[0] = 0  # don't regularize intercept theta\n",
    "\n",
    "    regularized_term = (l / m) * regularized_term\n",
    "\n",
    "    return gradient(theta, X, y) + regularized_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularized_gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拟合数据\n",
    "> 正则化项 $\\lambda=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_np(X, y, l=1):\n",
    "    \"\"\"linear regression\n",
    "    args:\n",
    "        X: feature matrix, (m, n+1) # with incercept x0=1\n",
    "        y: target vector, (m, )\n",
    "        l: lambda constant for regularization\n",
    "\n",
    "    return: trained parameters\n",
    "    \"\"\"\n",
    "    # init theta\n",
    "    theta = np.ones(X.shape[1])\n",
    "\n",
    "    # train it\n",
    "    res = opt.minimize(fun=regularized_cost,\n",
    "                       x0=theta,\n",
    "                       args=(X, y, l),\n",
    "                       method='TNC',\n",
    "                       jac=regularized_gradient,\n",
    "                       options={'disp': True})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_cost(theta, X, y, l=1):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    regularized_term = (l / (2 * m)) * np.power(theta[1:], 2).sum()\n",
    "\n",
    "    return cost(theta, X, y) + regularized_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones(X.shape[0])\n",
    "\n",
    "final_theta = linear_regression_np(X, y, l=0).get('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = final_theta[0] # intercept\n",
    "m = final_theta[1] # slope\n",
    "\n",
    "plt.scatter(X[:,1], y, label=\"Training data\")\n",
    "plt.plot(X[:, 1], X[:, 1]*m + b, label=\"Prediction\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cost, cv_cost = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.使用训练集的子集来拟合应模型\n",
    "\n",
    "2.在计算训练代价和交叉验证代价时，没有用正则化\n",
    "\n",
    "3.记住使用相同的训练集子集来计算训练代价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "for i in range(1, m+1):\n",
    "#     print('i={}'.format(i))\n",
    "    res = linear_regression_np(X[:i, :], y[:i], l=0)\n",
    "    \n",
    "    tc = regularized_cost(res.x, X[:i, :], y[:i], l=0)\n",
    "    cv = regularized_cost(res.x, Xval, yval, l=0)\n",
    "#     print('tc={}, cv={}'.format(tc, cv))\n",
    "    \n",
    "    training_cost.append(tc)\n",
    "    cv_cost.append(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, m+1), training_cost, label='training cost')\n",
    "plt.plot(np.arange(1, m+1), cv_cost, label='cv cost')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型拟合不太好, **欠拟合了**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建多项式特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_poly_data(*args, power):\n",
    "    \"\"\"\n",
    "    args: keep feeding in X, Xval, or Xtest\n",
    "        will return in the same order\n",
    "    \"\"\"\n",
    "    def prepare(x):\n",
    "        # expand feature\n",
    "        df = poly_features(x, power=power)\n",
    "\n",
    "        # normalization\n",
    "        ndarr = normalize_feature(df).as_matrix()\n",
    "\n",
    "        # add intercept term\n",
    "        return np.insert(ndarr, 0, np.ones(ndarr.shape[0]), axis=1)\n",
    "\n",
    "    return [prepare(x) for x in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_features(x, power, as_ndarray=False):\n",
    "    data = {'f{}'.format(i): np.power(x, i) for i in range(1, power + 1)}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df.as_matrix() if as_ndarray else df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, Xval, yval, Xtest, ytest = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features(X, power=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备多项式回归数据\n",
    "1. 扩展特征到 8阶,或者你需要的阶数\n",
    "2. 使用 **归一化** 来合并 $x^n$ \n",
    "3. don't forget intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature(df):\n",
    "    \"\"\"Applies function along input axis(default 0) of DataFrame.\"\"\"\n",
    "    return df.apply(lambda column: (column - column.mean()) / column.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly, Xval_poly, Xtest_poly= prepare_poly_data(X, Xval, Xtest, power=8)\n",
    "X_poly[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画出学习曲线\n",
    "> 首先，我们没有使用正则化，所以 $\\lambda=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(X, y, Xval, yval, l=0):\n",
    "    training_cost, cv_cost = [], []\n",
    "    m = X.shape[0]\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        # regularization applies here for fitting parameters\n",
    "        res = linear_regression_np(X[:i, :], y[:i], l=l)\n",
    "\n",
    "        # remember, when you compute the cost here, you are computing\n",
    "        # non-regularized cost. Regularization is used to fit parameters only\n",
    "        tc = cost(res.x, X[:i, :], y[:i])\n",
    "        cv = cost(res.x, Xval, yval)\n",
    "\n",
    "        training_cost.append(tc)\n",
    "        cv_cost.append(cv)\n",
    "\n",
    "    plt.plot(np.arange(1, m + 1), training_cost, label='training cost')\n",
    "    plt.plot(np.arange(1, m + 1), cv_cost, label='cv cost')\n",
    "    plt.legend(loc=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(X_poly, y, Xval_poly, yval, l=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以看到训练的代价太低了，不真实. 这是 **过拟合**了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try $\\lambda=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(X_poly, y, Xval_poly, yval, l=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "训练代价增加了些，不再是0了。\n",
    "也就是说我们减轻**过拟合**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try $\\lambda=100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(X_poly, y, Xval_poly, yval, l=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "太多正则化了.  \n",
    "变成 **欠拟合**状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找到最佳的 $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_candidate = [0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "training_cost, cv_cost = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in l_candidate:\n",
    "    res = linear_regression_np(X_poly, y, l)\n",
    "    \n",
    "    tc = cost(res.x, X_poly, y)\n",
    "    cv = cost(res.x, Xval_poly, yval)\n",
    "    \n",
    "    training_cost.append(tc)\n",
    "    cv_cost.append(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_candidate, training_cost, label='training')\n",
    "plt.plot(l_candidate, cv_cost, label='cross validation')\n",
    "plt.legend(loc=2)\n",
    "\n",
    "plt.xlabel('lambda')\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best cv I got from all those candidates\n",
    "l_candidate[np.argmin(cv_cost)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use test data to compute the cost\n",
    "for l in l_candidate:\n",
    "    theta = linear_regression_np(X_poly, y, l).x\n",
    "    print('test cost(l={}) = {}'.format(l, cost(theta, Xtest_poly, ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后， $\\lambda = 0.3$ 是最优选择，这个时候测试代价最小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "mlevn",
   "language": "python",
   "name": "mlevn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
