{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN back propagation（神经网络反向传播）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib\n",
    "import scipy.optimize as opt\n",
    "from sklearn.metrics import classification_report#这个包是评价报告\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取及处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, transpose=True):\n",
    "    '''\n",
    "    数据读取函数\n",
    "    '''\n",
    "    data = sio.loadmat(path)\n",
    "    y = data.get('y')  # (5000,1)\n",
    "    y = y.reshape(y.shape[0])  # make it back to column vector\n",
    "\n",
    "    X = data.get('X')  # (5000,400)\n",
    "\n",
    "    if transpose:\n",
    "        # for this dataset, you need a transpose to get the orientation right\n",
    "        X = np.array([im.reshape((20, 20)).T for im in X])\n",
    "\n",
    "        # and I flat the image again to preserve the vector presentation\n",
    "        X = np.array([im.reshape(400) for im in X])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400) (5000,)\n"
     ]
    }
   ],
   "source": [
    "X_original, y_original = load_data('ex4data1.mat', transpose=False)\n",
    "print(X_original.shape,y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 401)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.insert(X_original, 0, np.ones(X_original.shape[0]), axis=1)#增加全部为1的一列\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10) [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "Y = encoder.fit_transform(y_original.reshape(-1,1))\n",
    "print(Y.shape, Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weight(path):\n",
    "    data = sio.loadmat(path)\n",
    "    return data['Theta1'], data['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 401), (10, 26))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_1, theta_2 = load_weight('ex4weights.mat')\n",
    "theta_1.shape, theta_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将2个theta扁平化\n",
    "def serialize(a, b):\n",
    "    return np.concatenate((np.ravel(a), np.ravel(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10285,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = serialize(theta_1, theta_2)  # 扁平化参数，25*401+10*26=10285\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(theta):\n",
    "    theta_1 = theta[:25*401].reshape(25,401)\n",
    "    theta_2 = theta[25*401:].reshape(10, 26)\n",
    "    return theta_1,theta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(theta,X):\n",
    "    theta_1,theta_2 = deserialize(theta)\n",
    "    # z表示该层的输入，a表示该层的输出\n",
    "    a1 = X\n",
    "    # 第二层\n",
    "    z2 = X @ theta_1.T\n",
    "    a2 = np.insert(sigmoid(z2),0,np.ones(len(X)),axis=1)\n",
    "    #第三次 output层\n",
    "    z3 = a2 @ theta_2.T\n",
    "    output = sigmoid(z3)    \n",
    "    return a1,z2,a2,z3,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.12661530e-04, 1.74127856e-03, 2.52696959e-03, ...,\n",
       "        4.01468105e-04, 6.48072305e-03, 9.95734012e-01],\n",
       "       [4.79026796e-04, 2.41495958e-03, 3.44755685e-03, ...,\n",
       "        2.39107046e-03, 1.97025086e-03, 9.95696931e-01],\n",
       "       [8.85702310e-05, 3.24266731e-03, 2.55419797e-02, ...,\n",
       "        6.22892325e-02, 5.49803551e-03, 9.28008397e-01],\n",
       "       ...,\n",
       "       [5.17641791e-02, 3.81715020e-03, 2.96297510e-02, ...,\n",
       "        2.15667361e-03, 6.49826950e-01, 2.42384687e-05],\n",
       "       [8.30631310e-04, 6.22003774e-04, 3.14518512e-04, ...,\n",
       "        1.19366192e-02, 9.71410499e-01, 2.06173648e-04],\n",
       "       [4.81465717e-05, 4.58821829e-04, 2.15146201e-05, ...,\n",
       "        5.73434571e-03, 6.96288990e-01, 8.18576980e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, _, _, output = feed_forward(theta, X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y):\n",
    "    # get the data size m\n",
    "    _, _, _, _, h = feed_forward(theta, X)\n",
    "    pair_computation = -np.multiply(y, np.log(h)) - np.multiply((1 - y), np.log(1 - h))\n",
    "    return pair_computation.sum() / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2876291651613189"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(theta, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_regularize(theta, X, y,learn_rate=1):\n",
    "    theta_1, theta_2 = deserialize(theta)  # t1: (25,401) t2: (10,26)\n",
    "    m = X.shape[0]\n",
    "    reg_t1 = (learn_rate / (2 * m)) * np.power(theta_1[:, 1:], 2).sum()  # this is how you ignore first col\n",
    "    reg_t2 = (learn_rate / (2 * m)) * np.power(theta_2[:, 1:], 2).sum()\n",
    "    return cost(theta, X, y) + reg_t1 + reg_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38376985909092365"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_regularize(theta, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    \"\"\"\n",
    "    pairwise op is key for this to work on both vector and matrix\n",
    "    \"\"\"\n",
    "    return np.multiply(sigmoid(z), 1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y):\n",
    "    # 就是计算每一次两组theta应该减少多少\n",
    "    theta_1,theta_2 = deserialize(theta) #(25, 401), (10, 26)\n",
    "    m = len(X)\n",
    "    # 这就是最终返回的应该减去多少的值\n",
    "    delta_1 = np.zeros_like(theta_1)\n",
    "    delta_2 = np.zeros_like(theta_2)\n",
    "    \n",
    "    a_1, z_2, a_2, z_3, predicted = feed_forward(theta, X)\n",
    "    # 一个样本一个样本的累加\n",
    "    for i in range(m):\n",
    "        a_1_i = a_1[i, :]  # 输入层 (1, 401) \n",
    "        z_2_i = z_2[i, :]  # 第二层的输入(1, 25)\n",
    "        a_2_i = a_2[i, :]  # 第二层的输出(1, 26)\n",
    "        predicted_i = predicted[i, :]    # 预测层(1, 10)\n",
    "        y_i = y[i, :]    # 样本真实值(1, 10)\n",
    "        # 求预测层和中间隐藏层的预测差值\n",
    "        diff_3_i = predicted_i - y_i # (1, 10)\n",
    "        z_2_i = np.insert(z_2_i, 0, np.ones(1))\n",
    "        diff_2_i = np.multiply(theta_2.T @ diff_3_i,sigmoid_gradient(z_2_i))\n",
    "        \n",
    "        delta_2 += np.matrix(diff_3_i).T @ np.matrix(a_2_i)  # (1, 10).T @ (1, 26) -> (10, 26)\n",
    "        delta_1 += np.matrix(diff_2_i[1:]).T @ np.matrix(a_1_i)  # (1, 25).T @ (1, 401) -> (25, 401)\n",
    "\n",
    "    delta_1 = delta_1 / m\n",
    "    delta_2 = delta_2 / m\n",
    "\n",
    "    return serialize(delta_1, delta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2 = deserialize(gradient(theta, X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expend_array(x):\n",
    "    return np.array(np.matrix(np.ones(x.shape[0])).T @ np.matrix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度校验\n",
    "<img style=\"float: left;\" src=\"../img/gradient_checking.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradient(theta, X,y,epsilon, regularized=False):\n",
    "    def a_numeric_grad(plus, minus, regularized=False):\n",
    "        \"\"\"calculate a partial gradient with respect to 1 theta\"\"\"\n",
    "        if regularized:\n",
    "            return (cost_regularize(plus, X, y) - cost_regularize(minus, X, y)) / (epsilon * 2)\n",
    "        else:\n",
    "            return (cost(plus, X, y) - cost(minus, X, y)) / (epsilon * 2)\n",
    "    theta_matrix = expand_array(theta)  # expand to (10285, 10285)\n",
    "    epsilon_matrix = np.identity(len(theta)) * epsilon\n",
    "    plus_matrix = theta_matrix + epsilon_matrix\n",
    "    minus_matrix = theta_matrix - epsilon_matrix\n",
    "    # 计算约等号两边的值\n",
    "    numeric_grad = np.array([a_numeric_grad(plus_matrix[i], minus_matrix[i], regularized)\n",
    "                                    for i in range(len(theta))])\n",
    "\n",
    "    # analytical grad will depend on if you want it to be regularized or not\n",
    "    analytic_grad = regularized_gradient(theta, X, y) if regularized else gradient(theta, X, y)\n",
    "    diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad)\n",
    "\n",
    "    print('If your backpropagation implementation is correct,\\nthe relative difference will be smaller than 10e-9 (assume epsilon=0.0001).\\nRelative Difference: {}\\n'.format(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized gradient\n",
    "Use normal gradient + regularized term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../img/nn_reg_grad.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_gradient(theta, X, y, l=1):\n",
    "    \"\"\"don't regularize theta of bias terms\"\"\"\n",
    "    m = X.shape[0]\n",
    "    delta1, delta2 = deserialize(gradient(theta, X, y))\n",
    "    t1, t2 = deserialize(theta)\n",
    "\n",
    "    t1[:, 0] = 0\n",
    "    reg_term_d1 = (l / m) * t1\n",
    "    delta1 = delta1 + reg_term_d1\n",
    "\n",
    "    t2[:, 0] = 0\n",
    "    reg_term_d2 = (l / m) * t2\n",
    "    delta2 = delta2 + reg_term_d2\n",
    "\n",
    "    return serialize(delta1, delta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init(size):\n",
    "    return np.random.uniform(-0.12, 0.12, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_training(X, y):\n",
    "    \"\"\"regularized version\n",
    "    the architecture is hard coded here... won't generalize\n",
    "    \"\"\"\n",
    "    init_theta = random_init(10285)  # 25*401 + 10*26\n",
    "\n",
    "    res = opt.minimize(fun=cost_regularize,\n",
    "                       x0=init_theta,\n",
    "                       args=(X,Y, 1),\n",
    "                       method='TNC',\n",
    "                       jac=regularized_gradient,\n",
    "                       options={'maxiter': 400})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.3136198591123115\n",
       "     jac: array([-8.65416595e-05, -7.55279286e-08, -2.60001165e-07, ...,\n",
       "       -1.09773604e-05,  4.96631233e-05,  9.88057706e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 400\n",
       "     nit: 27\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([ 0.00000000e+00, -3.77639643e-04, -1.30000583e-03, ...,\n",
       "       -4.16178230e+00,  1.77502417e+00,  8.33586961e-01])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = nn_training(X, Y)#慢\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlevn",
   "language": "python",
   "name": "mlevn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
